Hackathon submission (17/12/2024) for tip deconvolution.

In this hackathon submission, we focus on mitigating tip-induced artifacts in AFM images, particularly those arising from blunt or imperfectly shaped tips. The dataset consists of a single AFM scan of unspecified lateral dimensions, from which we generate synthetic training examples by convolving the original image with a Gaussian kernel. The Gaussian’s standard deviation (tip radius) and center coordinates are randomly sampled from a uniform distribution in [0.2, 0.8), enabling controlled generation of blunt tip artifacts. Although we intended to model double-tip artifacts as well, time constraints precluded this addition.

We acknowledge that using a single image for training may lead to substantial overfitting, and thus any derived metrics should be interpreted with caution. Nonetheless, our primary objective was to explore the feasibility of autoencoder-based solutions. Drawing on established literature, we tested various architectures and loss functions, notably combining MAE and SSIM metrics. As a comparative baseline, we employed Gwyddion’s tip estimation and surface reconstruction methods on select images and contrasted these with our trained models’ outputs.

Additionally, we extended the same methodology to an experimental STM dataset, artificially introducing blunt tip defects as a preliminary proof of concept for transferability to other scanning probe or electron microscopy techniques. While initial STM results appear promising, further research is necessary to address specific artifacts associated with STM tip geometries and to rigorously evaluate the approach’s generalizability.
